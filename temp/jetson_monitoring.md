ë„¤, ê°œë°œìë‹˜ì˜ ì§ê°ì´ ì •í™•í•˜ì‹­ë‹ˆë‹¤. **`tegrastats`ì˜ í…ìŠ¤íŠ¸ ì¶œë ¥(String)ì„ íŒŒì´ì¬ìœ¼ë¡œ íŒŒì‹±(Parsing)í•˜ëŠ” ë°©ì‹ì€ "ì ˆëŒ€ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."**

ì´ìœ ëŠ” ê°„ë‹¨í•©ë‹ˆë‹¤. JetPack ë²„ì „ì´ ì—…ë°ì´íŠ¸ë˜ê±°ë‚˜, íŠ¹ì • ì„¼ì„œê°€ ì ì‹œ êº¼ì§€ë©´ í…ìŠ¤íŠ¸ í¬ë§·(ë„ì–´ì“°ê¸°, ìˆœì„œ)ì´ ë°”ë€Œì–´ë²„ë ¤ì„œ ì½”ë“œê°€ ë»—ì–´ë²„ë¦´(Exception) ìœ„í—˜ì´ ë§¤ìš° í¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ê°€ì¥ **Robust(ê²¬ê³ )í•˜ê³  Industry Standard(ì‚°ì—… í‘œì¤€)**ì— ê°€ê¹Œìš´ ë°©ë²•ì€ ë‘ ê°€ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ **"í˜¼í•©(Hybrid)"**í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

1. **ë²”ìš© ì‹œìŠ¤í…œ(CPU, RAM, Network):** Python í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ **`psutil`** ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì ).
2. **Jetson íŠ¹í™” í•˜ë“œì›¨ì–´(GPU, Power, Fan):** **`jtop` (jetson-stats)ì˜ Python API** ì‚¬ìš© (NVIDIA ì‹œìŠ¤í…œ íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì½ì–´ì˜¤ëŠ” Wrapper).

ì´ ë‘ ê°€ì§€ë¥¼ ì¡°í•©í•˜ì—¬, ì—ëŸ¬ í•¸ë“¤ë§ê¹Œì§€ í¬í•¨ëœ **"í˜„ì¡´í•˜ëŠ” ê°€ì¥ ì•ˆì „í•œ ëª¨ë‹ˆí„°ë§ ì½”ë“œ"**ë¥¼ ì‘ì„±í•´ ë“œë¦½ë‹ˆë‹¤.

---

### ğŸ›¡ï¸ Robust System Monitor Node (Final Version)

ì´ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤.

* **Safe Reading:** ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ ë…¸ë“œê°€ ì£½ì§€ ì•Šê³  `None` ë˜ëŠ” `0`ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
* **Non-Blocking:** Pingì´ë‚˜ ë„¤íŠ¸ì›Œí¬ ì²´í¬ê°€ ì˜¤ë˜ ê±¸ë ¤ë„ ROS ë£¨í”„ë¥¼ ë§‰ì§€ ì•Šë„ë¡ íƒ€ì„ì•„ì›ƒì„ ì§§ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.
* **Rolling Statistics:** Avg, Max ê³„ì‚°ì„ ìœ„í•´ ìµœê·¼ 60ê°œì˜ ë°ì´í„°ë§Œ ë©”ëª¨ë¦¬ í(Deque)ì— ë³´ê´€í•©ë‹ˆë‹¤.

```python
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import json
import psutil
import subprocess
import time
from collections import deque
from jtop import jtop

class RobustMonitor(Node):
    def __init__(self):
        super().__init__('robust_system_monitor')
        
        # 1. ì„¤ì •
        self.declare_parameter('target_ip', '192.168.0.1') # IPC í˜¹ì€ ê³µìœ ê¸° IP
        self.target_ip = self.get_parameter('target_ip').value
        self.interval = 1.0 # 1ì´ˆ ì£¼ê¸°
        
        # 2. ë°ì´í„° ì €ì¥ì„ ìœ„í•œ í (ìµœê·¼ 60ì´ˆ ë°ì´í„° ë³´ê´€ -> Avg/Max ê³„ì‚°ìš©)
        # dequeë¥¼ ì“°ë©´ maxlen ë„˜ì–´ê°€ë©´ ì•Œì•„ì„œ ì˜¤ë˜ëœ ê²ƒ ë²„ë¦¼ (ë©”ëª¨ë¦¬ ì•ˆì „)
        self.history_len = 60
        self.cpu_q = deque(maxlen=self.history_len)
        self.gpu_q = deque(maxlen=self.history_len)
        
        # 3. ë„¤íŠ¸ì›Œí¬ ì†ë„ ê³„ì‚°ìš© ì´ì „ ìƒíƒœ
        self.prev_net = psutil.net_io_counters()
        self.prev_time = time.time()

        # 4. Jtop (GPU ëª¨ë‹ˆí„°ë§) ì•ˆì „í•˜ê²Œ ì‹œì‘
        try:
            self.jetson = jtop()
            self.jetson.start()
            if not self.jetson.ok():
                self.get_logger().error("Jtop Service is NOT running. GPU stats will be empty.")
        except Exception as e:
            self.get_logger().error(f"Failed to start Jtop: {e}")
            self.jetson = None

        # 5. Timer ë° Publisher
        self.pub = self.create_publisher(String, 'system_status', 10)
        self.timer = self.create_timer(self.interval, self.update_stats)

        self.get_logger().info("Robust System Monitor Started.")

    def _get_network_metrics(self):
        """psutilì„ ì´ìš©í•œ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ê³„ì‚° (ê°€ì¥ ì •í™•í•¨)"""
        try:
            curr_net = psutil.net_io_counters()
            curr_time = time.time()
            dt = curr_time - self.prev_time
            
            if dt <= 0: dt = 1.0 # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€

            sent_bps = (curr_net.bytes_sent - self.prev_net.bytes_sent) / dt
            recv_bps = (curr_net.bytes_recv - self.prev_net.bytes_recv) / dt

            self.prev_net = curr_net
            self.prev_time = curr_time

            return {
                "tx_mbps": round(sent_bps * 8 / 1_000_000, 2), # Mbps ë³€í™˜
                "rx_mbps": round(recv_bps * 8 / 1_000_000, 2),
                "tx_total_mb": round(curr_net.bytes_sent / 1024 / 1024, 1),
                "rx_total_mb": round(curr_net.bytes_recv / 1024 / 1024, 1)
            }
        except Exception as e:
            self.get_logger().warn(f"Net Error: {e}")
            return {}

    def _get_latency_and_sync(self):
        """Subprocessë¥¼ ì‚¬ìš©í•˜ë˜ Timeoutì„ ê±¸ì–´ ì•ˆì „í•˜ê²Œ ì¸¡ì •"""
        ping_ms = -1.0
        sync_offset_ms = 0.0

        # 1. Network Latency (Ping)
        try:
            # íƒ€ì„ì•„ì›ƒ 0.5ì´ˆë¡œ ë§¤ìš° ì§§ê²Œ ì„¤ì •í•˜ì—¬ ROS ë£¨í”„ ì§€ì—° ë°©ì§€
            cmd = ['ping', '-c', '1', '-W', '1', self.target_ip]
            res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=1.1)
            if res.returncode == 0:
                # time=12.3 ms íŒŒì‹±
                start = res.stdout.find('time=')
                if start != -1:
                    end = res.stdout.find(' ms', start)
                    ping_ms = float(res.stdout[start+5:end])
        except Exception:
            ping_ms = -1.0 # ì‹¤íŒ¨ ì‹œ -1 í‘œê¸°

        # 2. Time Sync (Chrony)
        try:
            cmd = ['chronyc', 'tracking']
            res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=0.5)
            if res.returncode == 0:
                for line in res.stdout.splitlines():
                    if "Last offset" in line:
                        # "+0.000012 seconds" -> ms ë³€í™˜
                        parts = line.split(':')
                        if len(parts) > 1:
                            seconds = float(parts[1].replace('seconds', '').strip())
                            sync_offset_ms = seconds * 1000.0
                        break
        except Exception:
            sync_offset_ms = 9999.9 # ì‹¤íŒ¨ ì‹œ í° ê°’ í˜¹ì€ ì‹ë³„ê°’

        return ping_ms, sync_offset_ms

    def update_stats(self):
        # 1. CPU & RAM (psutil ì‚¬ìš© - ë§¤ìš° ì•ˆì •ì )
        cpu_cur = psutil.cpu_percent(interval=None) # interval=Noneì€ non-blocking
        self.cpu_q.append(cpu_cur)
        
        mem = psutil.virtual_memory() # ì „ì²´ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬
        
        # 2. GPU & Power (jtop ì‚¬ìš© - Jetson íŠ¹í™”)
        gpu_cur = 0
        gpu_temp = 0
        gpu_mem = 0
        power_w = 0
        
        if self.jetson and self.jetson.ok():
            try:
                # GPU ë¡œë“œìœ¨
                gpu_cur = self.jetson.stats['GPU']
                self.gpu_q.append(gpu_cur)
                
                # ì˜¨ë„ ë° ë©”ëª¨ë¦¬
                gpu_temp = self.jetson.stats['Temp'].get('GPU', 0)
                # jtopì˜ RAM['shared']ê°€ GPU ì‚¬ìš©ëŸ‰ê³¼ ìœ ì‚¬ (Unified Memory)
                gpu_mem = self.jetson.stats['RAM'].get('shared', 0) / 1024 # MB
                
                # ì „ë ¥
                power_w = self.jetson.stats['Power'].get('avg', 0) / 1000 # Watt
            except KeyError:
                pass # íŠ¹ì • í•„ë“œê°€ ì—†ì–´ë„ ì£½ì§€ ì•ŠìŒ

        # 3. Network & Sync
        net_metrics = self._get_network_metrics()
        ping, time_offset = self._get_latency_and_sync()

        # 4. í†µê³„ ê³„ì‚° (Safe division)
        cpu_avg = sum(self.cpu_q) / len(self.cpu_q) if self.cpu_q else 0
        cpu_max = max(self.cpu_q) if self.cpu_q else 0
        
        gpu_avg = sum(self.gpu_q) / len(self.gpu_q) if self.gpu_q else 0
        gpu_max = max(self.gpu_q) if self.gpu_q else 0

        # 5. ìµœì¢… ë©”ì‹œì§€ ìƒì„±
        status_data = {
            "timestamp": time.time(),
            "cpu": {
                "usage_percent": cpu_cur,
                "avg_60s": round(cpu_avg, 1),
                "max_60s": round(cpu_max, 1),
                "mem_usage_mb": round(mem.used / 1024 / 1024, 1),
                "mem_percent": mem.percent
            },
            "gpu": {
                "usage_percent": int(gpu_cur),
                "avg_60s": round(gpu_avg, 1),
                "max_60s": int(gpu_max),
                "temp_c": int(gpu_temp),
                "mem_usage_mb": int(gpu_mem)
            },
            "network": {
                "io": net_metrics,
                "latency_ping_ms": ping,
            },
            "system": {
                "time_offset_ms": round(time_offset, 4),
                "power_w": round(power_w, 2)
            }
        }

        # JSON Publish
        msg = String()
        msg.data = json.dumps(status_data)
        self.pub.publish(msg)

    def destroy_node(self):
        if self.jetson:
            self.jetson.close()
        super().destroy_node()

def main(args=None):
    rclpy.init(args=args)
    node = RobustMonitor()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()

```

---

### ğŸ’¡ ì™œ ì´ ë°©ì‹ì´ ê°€ì¥ Robustí•œê°€?

1. **`psutil` (Standard Library):**
* `cpu_percent`ë‚˜ `net_io_counters`ëŠ” ë¦¬ëˆ…ìŠ¤ ì»¤ë„ì˜ `/proc/stat`, `/proc/net/dev` íŒŒì¼ì„ ì§ì ‘ ì½ìŠµë‹ˆë‹¤. `tegrastats`ì²˜ëŸ¼ ì¶œë ¥ í¬ë§·ì´ ë³€í•  ì¼ì´ **ì „í˜€** ì—†ìŠµë‹ˆë‹¤. Python ìƒíƒœê³„ í‘œì¤€ì…ë‹ˆë‹¤.


2. **`jtop` Library (API Access):**
* `tegrastats` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì„œ í…ìŠ¤íŠ¸ë¥¼ ê¸ì–´ì˜¤ëŠ” ê²Œ ì•„ë‹ˆë¼, **`jetson-stats` ë°ëª¬(jtop service)ê³¼ ì†Œì¼“ í†µì‹ **ì„ í•˜ê±°ë‚˜ ì‹œìŠ¤í…œ íŒŒì¼ì„ ì§ì ‘ ì½ìŠµë‹ˆë‹¤. í›¨ì”¬ ë¹ ë¥´ê³  í¬ë§· ë³€ê²½ì— ì•ˆì „í•©ë‹ˆë‹¤.
* **Context Manager:** `try-except` ë¸”ë¡ ì•ˆì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ, GPU ì„¼ì„œ í•˜ë‚˜ê°€ ê³ ì¥ ë‚˜ë”ë¼ë„ CPU ëª¨ë‹ˆí„°ë§ì€ ê³„ì† ì‚´ì•„ì„œ ëŒì•„ê°‘ë‹ˆë‹¤.


3. **Deque (Double-ended Queue):**
* ë¦¬ìŠ¤íŠ¸ì— `append`ë§Œ ê³„ì†í•˜ë©´ ë©”ëª¨ë¦¬ê°€ í„°ì§‘ë‹ˆë‹¤. `deque(maxlen=60)`ì„ ì‚¬ìš©í•˜ì—¬ **ìë™ìœ¼ë¡œ ì˜¤ë˜ëœ ë°ì´í„°ë¥¼ ì‚­ì œ**í•˜ë¯€ë¡œ ë©°ì¹ ì„ ì¼œë‘¬ë„ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.



ì´ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì‹œë©´ ZED, Nav2ì™€ í•¨ê»˜ ëª‡ ë‹¬ì„ ëŒë ¤ë†”ë„ ëª¨ë‹ˆí„°ë§ ë…¸ë“œ ë•Œë¬¸ì— ì‹œìŠ¤í…œì´ ì£½ëŠ” ì¼ì€ ì—†ì„ ê²ƒì…ë‹ˆë‹¤.
